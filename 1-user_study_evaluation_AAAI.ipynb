{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Import The Libraries / Load the Data / Housekeeping](#1.-Import-The-Libraries-/-Load-the-Data-/-Housekeeping)\n",
    "2. [Define Helpful Functions](#2.-Define-Helpful-Functions)\n",
    "3. [Some First Eyeballing](#3.-Some-First-Eyeballing)\n",
    "4. [Data Cleaning](#4.-Data-Cleaning) \n",
    "5. [Eyeballing After Cleaning](#5.-Eyeballing-After-Cleaning)\n",
    "6. [Descriptive Statistics](#6.-Descriptive-Statistics)\n",
    "    - [Average Time Needed](#Average-Time-Needed)\n",
    "    - [Visualize Demographics](#Visualize-Demographics-(before-and-after-cleaning))\n",
    "    - [Test For Gender Differences](#Test-For-Gender-Differences)\n",
    "\n",
    "\n",
    "7. [Statistical Analysis (finally!)](#7.-Statistical-Analysis-(finally!))\n",
    "    - [First: Trust](#First:-Trust)\n",
    "    - [Second: Response Time](#Second:-Response-Time)\n",
    "\n",
    "\n",
    "8. [How to Report Results in a Paper?](#8.-How-to-Report-Results-in-a-Paper?) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCxVWdgs2dDG"
   },
   "source": [
    "# 1. Import The Libraries / Load the Data / Housekeeping\n",
    "First, we'll load all the CSV files into pandas DataFrames. We will also do some slight re-coding of the data for easier processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy matplotlib seaborn scipy scikit_posthocs statsmodels rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPlTh7jO2RAW"
   },
   "outputs": [],
   "source": [
    "# Step A: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "reaction_times_task = pd.read_csv('https://raw.githubusercontent.com/ukuhl/AAAI_CF_Tutorial/main/reaction_time_data_AAAI.csv')\n",
    "trust_data = pd.read_csv('https://raw.githubusercontent.com/ukuhl/AAAI_CF_Tutorial/main/trust_data_AAAI.csv')\n",
    "\n",
    "# Define a consistent color palette for consistent plotting\n",
    "color_palette = {\n",
    "    'No-XP': '#1f77b4',  # blue\n",
    "    'CF-XP': '#ff7f0e',  # orange\n",
    "}\n",
    "\n",
    "# Convert the palette to a list of colors\n",
    "colors = [color_palette[key] for key in color_palette]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trust_data)\n",
    "print(reaction_times_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for eyeballing data / plotting\n",
    "def get_ylim(data, group_column, value_column):\n",
    "    grouped = data.groupby(group_column)[value_column].agg(['mean', 'sem']).reset_index()\n",
    "    max_ylim = (grouped['mean'] + 1.5*grouped['sem']).max()\n",
    "    return 0, max_ylim\n",
    "\n",
    "def get_material_ylim(data, group_column, material_column, value_column):\n",
    "    grouped = data.groupby([group_column, material_column])[value_column].agg(['mean', 'sem']).reset_index()\n",
    "    max_ylim = (grouped['mean'] + 1.2*grouped['sem']).max()\n",
    "    return 0, max_ylim\n",
    "\n",
    "# for data cleaning, remove outliers\n",
    "def identify_outliers(df, column):\n",
    "    # define the factor with which std will be multiplied to find admissible range\n",
    "    removal_factor_population=3\n",
    "    print(\"\\nMeasure: \" + column)\n",
    "    print(\"Population mean: \" + str(round(df[column].mean(),3)))\n",
    "    print(\"Population std: \" + str(round(df[column].std(),3)))\n",
    "    print(\"Admissible range: \" + str(round(df[column].mean()-removal_factor_population * df[column].std())) + \" -- \" + str(round(df[column].mean()+removal_factor_population * df[column].std())))\n",
    "    #outliers = df[np.abs(df[column] - df[column].mean()) > (3 * df[column].std())]\n",
    "    outliers = df[df[column] < (df[column].mean() - removal_factor_population * df[column].std())]\n",
    "    return outliers['Participant'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Some First Eyeballing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at Data For Individual Participants\n",
    "unique_participants = trust_data.drop_duplicates(subset='Participant')\n",
    "\n",
    "# Plot Gender distribution\n",
    "print('\\n Plot Gender distribution')\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=unique_participants, x='Gender', hue='Group', palette=color_palette)\n",
    "plt.title('Gender Distribution by Condition')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Look at Trust\n",
    "#plt.figure(figsize=(8, 4))\n",
    "print('\\n Plot Trust Values')\n",
    "plt.figure(figsize=(8, 4))\n",
    "# Compute and plot mean trust per group\n",
    "mean_trust_per_user = trust_data.groupby(['Participant','Group'])['Trust'].mean().reset_index()\n",
    "sns.barplot(data=mean_trust_per_user, x='Group', y='Trust', palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Trust per User by Condition')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Mean Trust')\n",
    "plt.ylim(get_ylim(mean_trust_per_user, 'Group', 'Trust'))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# A closer look: what about individual participants?\n",
    "# Plot Trust per Participant\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Participant', y='Trust', hue='Group', data=trust_data, palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Trust per Participant')\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Trust')\n",
    "plt.ylim(0,max(trust_data['Trust'])+.2)\n",
    "plt.legend(title='Condition')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Look at Reaction Times\n",
    "# get ylims\n",
    "max_ylim_times_mean=get_ylim(reaction_times_task, 'Group', 'ReactionTime')\n",
    "max_ylim_times=get_material_ylim(reaction_times_task, 'Group', 'Material', 'ReactionTime')\n",
    "max_ylim_trust=get_material_ylim(trust_data, 'Group', 'Material','Trust',)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "# Plot Reaction Times per Group\n",
    "print('\\n Plot Reaction Times')\n",
    "sns.barplot(data=reaction_times_task, x='Group', y='ReactionTime', palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Response Time by Condition')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Response Time (ms)')\n",
    "plt.ylim(max_ylim_times_mean)\n",
    "\n",
    "# Plot Response Time per Material divided by group (to spot Effects Related to Materials)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Material', y='ReactionTime', hue='Group', data=reaction_times_task, palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Response Time per Material Number')\n",
    "plt.xlabel('Material Number')\n",
    "plt.ylabel('Response Time (ms)')\n",
    "plt.ylim(max_ylim_times)\n",
    "plt.legend(title='Condition')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# A closer look: what about individual participants?\n",
    "# Plot Respone time per Participant (to spot Effects Related to Participants)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Participant', y='ReactionTime', hue='Group', data=reaction_times_task, palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Response Time per Participant')\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Response Time')\n",
    "plt.ylim(0,max(reaction_times_task['ReactionTime'])+2)\n",
    "plt.legend(title='Condition')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUcuSYgP_6q3"
   },
   "source": [
    "# 4. Data Cleaning\n",
    "Next, we'll clean the data based on pre-defined criteria.\n",
    "\n",
    "#### Outliers relative to population mean\n",
    "Specifically, we want to remove:\n",
    "\n",
    "- all speedsters  >3 SDs below the mean​\n",
    "- straight-liners, repeatedly giving same answer​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ubYCNb3722uV",
    "outputId": "e11a6836-b671-4bc8-c058-d0a78ea3059d"
   },
   "outputs": [],
   "source": [
    "# Identify speedsters: >3 SDs from population mean\n",
    "outliers_reaction_times_task = set()\n",
    "for column in ['ReactionTime']:\n",
    "    outliers_reaction_times_task.update(identify_outliers(reaction_times_task, column))\n",
    "    \n",
    "print(\"UserIDs of speedsters relative to all participants (task) :\" + str(outliers_reaction_times_task))\n",
    "\n",
    "# Identify straightliners (repeatedly giving the same trust judgements)\n",
    "print(\"\\nStraightlining behavior:\")\n",
    "# Identify straightliners (repeatedly giving the same trust judgements)\n",
    "straightliners_task = trust_data.groupby('Participant').filter(lambda x: (x['Trust'].var() == 0))\n",
    "print(\"Participants straightlining during task: \" + str(straightliners_task['Participant'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all population outliers\n",
    "all_outliers = outliers_reaction_times_task.union(straightliners_task['Participant'].unique())\n",
    "\n",
    "print(\"Participants marked as outliers: \" + str(all_outliers))\n",
    "print(\"N: \" + str(len(all_outliers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove population outliers from all datasets\n",
    "reaction_times_task_cleaned = reaction_times_task[~reaction_times_task['Participant'].isin(all_outliers)]\n",
    "trust_data_cleaned = trust_data[~trust_data['Participant'].isin(all_outliers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wonky Materials?\n",
    "*Disclaimer: for time reasons, this part is not presented during the AAAI tutorial. For completion and later reference, we present the code here.*\n",
    "\n",
    "Are there any that are systematically answered unusually quickly?\n",
    "Here, we want to figure out if there are:\n",
    "\n",
    "- any materials  >3 SDs from polulation mean\n",
    "- any materials >3 SDs from person‘s own mean (to catch attention failures of individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify wonky materials: RTs >3 SDs from person‘s own mean\n",
    "# Define the factor with which std will be multiplied to find the admissible range\n",
    "removal_factor_user_wise = 3\n",
    "wonky_trial_user_percentage = 30\n",
    "\n",
    "# Identify trials (=materials) where users performed more quickly than > 3SD from their own RT mean\n",
    "reaction_time_outliers = reaction_times_task_cleaned[\n",
    "    reaction_times_task_cleaned['ReactionTime'] < (\n",
    "        reaction_times_task_cleaned.groupby('Participant')['ReactionTime'].transform('mean') - \n",
    "        removal_factor_user_wise * reaction_times_task_cleaned.groupby('Participant')['ReactionTime'].transform('std')\n",
    "    )\n",
    "]\n",
    "\n",
    "# Display the outliers for Response Time\n",
    "print(\"\\nParticipants + Material of speedsters relative to own performance (response time):\")\n",
    "print(reaction_time_outliers[['Participant', 'Material', 'ReactionTime']])\n",
    "\n",
    "## Calculate the percentage of outliers for each Material(=material)\n",
    "outlier_percentage = reaction_time_outliers['Material'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Identify Material(=material) where at least 30% of participants were quicker than > 3 SDs of their own performance\n",
    "wonky_trials = outlier_percentage[outlier_percentage >= wonky_trial_user_percentage].index.tolist()\n",
    "\n",
    "print(\"\\nList of Material where at least 30% of participants were quicker than > 3 SDs of their own performance:\")\n",
    "print(wonky_trials)\n",
    "\n",
    "## Show specifics of wonky_trials (=material)\n",
    "wonky_trials_df = trust_data_cleaned[trust_data_cleaned['Material'].isin(wonky_trials)].groupby('Material').head(1)\n",
    "print(\"\\nSpecifics of wonky materials:\")\n",
    "print(wonky_trials_df)\n",
    "\n",
    "# Filter out wonky trials from the dataframes - CAREFUL! LIKELY BREAKS BALANCE OF TRIALS!\n",
    "def remove_wonky_trials(df, wonky_trials):\n",
    "    return df[~df['Material'].isin(wonky_trials)]\n",
    "# Remove wonky trials from all relevant dataframes\n",
    "reaction_times_task_cleaned = remove_wonky_trials(reaction_times_task_cleaned, wonky_trials)\n",
    "trust_data_cleaned = remove_wonky_trials(trust_data_cleaned, wonky_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Eyeballing After Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at Data For Individual Participants\n",
    "unique_participants_cleaned = trust_data_cleaned.drop_duplicates(subset='Participant')\n",
    "\n",
    "# Plot Gender distribution\n",
    "print('\\n Plot Gender distribution')\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=unique_participants_cleaned, x='Gender', hue='Group', palette=color_palette)\n",
    "plt.title('Gender Distribution by Condition')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Look at Trust\n",
    "print('\\n Plot Trust Values')\n",
    "plt.figure(figsize=(8, 4))\n",
    "# Compute and plot mean trust per group\n",
    "mean_trust_per_user = trust_data_cleaned.groupby(['Participant','Group'])['Trust'].mean().reset_index()\n",
    "sns.barplot(data=mean_trust_per_user, x='Group', y='Trust', palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Trust per User by Condition')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Mean Trust')\n",
    "plt.ylim(get_ylim(mean_trust_per_user, 'Group', 'Trust'))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# A closer look: what about individual participants?\n",
    "# Plot Trust per Participant\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Participant', y='Trust', hue='Group', data=trust_data_cleaned, palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Trust per Participant')\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Trust')\n",
    "plt.ylim(0,max(trust_data_cleaned['Trust'])+.2)\n",
    "plt.legend(title='Condition')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Look at Reaction Times\n",
    "# get ylims\n",
    "max_ylim_times_mean=get_ylim(reaction_times_task_cleaned, 'Group', 'ReactionTime')\n",
    "max_ylim_times=get_material_ylim(reaction_times_task_cleaned, 'Group', 'Material', 'ReactionTime')\n",
    "max_ylim_trust=get_material_ylim(trust_data_cleaned, 'Group', 'Material','Trust',)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "# Plot Reaction Times per Group\n",
    "print('\\n Plot Reaction Times')\n",
    "sns.barplot(data=reaction_times_task_cleaned, x='Group', y='ReactionTime', palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Response Time by Condition')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Response Time (ms)')\n",
    "plt.ylim(max_ylim_times_mean)\n",
    "\n",
    "# Plot Response Time per Material divided by group (to spot Effects Related to Materials)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Material', y='ReactionTime', hue='Group', data=reaction_times_task_cleaned, palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Response Time per Material Number')\n",
    "plt.xlabel('Material Number')\n",
    "plt.ylabel('Response Time (ms)')\n",
    "plt.ylim(max_ylim_times)\n",
    "plt.legend(title='Condition')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# A closer look: what about individual participants?\n",
    "# Plot Respone time per Participant (to spot Effects Related to Participants)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Participant', y='ReactionTime', hue='Group', data=reaction_times_task_cleaned, palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Response Time per Participant')\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Response Time')\n",
    "plt.ylim(0,max(reaction_times_task_cleaned['ReactionTime'])+2)\n",
    "plt.legend(title='Condition')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9IrlWuKLF-3"
   },
   "source": [
    "# 6. Descriptive Statistics\n",
    "We'll compute descriptive statistics for the demographics and check if groups are significantly different in terms of age and gender.\n",
    "\n",
    "## Average Time Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_per_participant = reaction_times_task_cleaned.groupby('Participant')['ReactionTime'].sum()\n",
    "mean_total_time = sums_per_participant.mean()\n",
    "sd_total_time = sums_per_participant.std()\n",
    "print(mean_total_time)\n",
    "print('Mean +/- SD total time needed per participant:')\n",
    "print(str(round(mean_total_time/60,2)) + ' minutes +/- '+str(round(sd_total_time/60,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Demographics (before and after cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Provide a summary of the number of participants in each group\n",
    "participant_summary = unique_participants_cleaned.groupby(['Group','Gender']).size().reset_index(name='Number of Participants')\n",
    "\n",
    "print(\"\\nSummary of the number of participants in each group:\")\n",
    "print(participant_summary)\n",
    "\n",
    "# Plot: After data cleaning\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Plot Gender Distibution again, as a reminder:\n",
    "print('\\n Plot Gender distribution')\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(data=unique_participants, x='Gender', hue='Group', palette=color_palette)\n",
    "plt.title('Before Cleaning: Gender Distribution')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(data=unique_participants_cleaned, x='Gender', hue='Group', palette=color_palette)\n",
    "plt.title('After Cleaning: Gender Distribution')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test For Gender Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency, chi2, norm, shapiro, levene, kruskal\n",
    "\n",
    "# Chi-Square Test of Independence for Gender Distributions\n",
    "contingency_table = pd.crosstab(trust_data_cleaned['Group'], trust_data_cleaned['Gender'])\n",
    "chi2_test_result = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi^2 Test of Independence for Gender Distributions:\")\n",
    "print(f\"Chi^2 Statistic: {round(chi2_test_result[0],3)}, p-value: {round(chi2_test_result[1],3)}\")\n",
    "# if p > 0.05, H0 holds: we can assume that there is no dependence between Gender and Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** As p > 0.05 in the Chi^2 test, we can assume that there is no dependence between the gender and groups. Thus, we don't need to account for gender further as a covariate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Statistical Analysis (finally!)\n",
    "We'll analyze potential group differences in terms of\n",
    "* reported trust in the system and\n",
    "* response time\n",
    "\n",
    "## First: Trust\n",
    "\n",
    "We will kick-off with the trust judgements between groups first.\n",
    "\n",
    "### Step 1: Plot again to refresh our memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at Trust\n",
    "#plt.figure(figsize=(8, 4))\n",
    "print('\\n Plot Trust Values')\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "# Compute and plot mean trust per group\n",
    "mean_trust_per_user = trust_data_cleaned.groupby(['Participant','Group'])['Trust'].mean().reset_index()\n",
    "sns.barplot(data=mean_trust_per_user, x='Group', y='Trust', palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Trust per User by Condition')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Mean Trust')\n",
    "plt.ylim(get_ylim(mean_trust_per_user, 'Group', 'Trust'))\n",
    "\n",
    "# A closer look: what about individual participants?\n",
    "# Plot Trust per Participant\n",
    "#plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Participant', y='Trust', hue='Group', data=trust_data_cleaned, palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Trust per Participant')\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Trust')\n",
    "plt.ylim(0,max(trust_data_cleaned['Trust'])+.2)\n",
    "plt.legend(title='Condition')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Simple two-group case - what test to use?\n",
    "\n",
    "Given that responses were on a Likert-scale (\"strongly disagree - strongly agree\"), the rule of thumb is to use the non-parametric Mann Whitney U Test. As a non-parametric test, it has the advantage that is has fewer assumptions. E.g., the difference in group size after removal of dodgy data is not a problem.\n",
    "(Refer to basic statistics books / classes when deciding which tests to use when and why).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Aggregate the Trust Measure per Participant\n",
    "participant_trust = trust_data_cleaned.groupby(['Participant', 'Group'])['Trust'].mean().reset_index()\n",
    "participant_trust_mean = participant_trust.groupby(['Group'])['Trust'].mean().reset_index()\n",
    "participant_trust_sd = participant_trust.groupby(['Group'])['Trust'].std().reset_index()\n",
    "\n",
    "print(\"\\nAggregated Trust Data\")\n",
    "print(\"Means:\")\n",
    "print(participant_trust_mean)\n",
    "print(\"Std:\")\n",
    "print(participant_trust_sd)\n",
    "\n",
    "# Separate Trust Scores for Groups\n",
    "trust_no_xp = participant_trust.loc[participant_trust['Group'] == 'No-XP', 'Trust']\n",
    "trust_cf_xp = participant_trust.loc[participant_trust['Group'] == 'CF-XP', 'Trust']\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "stat, p_val = mannwhitneyu(trust_no_xp, trust_cf_xp, alternative='two-sided')\n",
    "\n",
    "print(f\"\\nMann-Whitney U statistic: {stat:.3f}, p-value: {p_val:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "Sucess! We can now report that reported trust between groups did indeed differ, with the Counterfactual group reporting significanly higher trust values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second: Response Time\n",
    "\n",
    "We will continue the response times differences between groups.\n",
    "\n",
    "### Step 1: Plot again to refresh our memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Reaction Times per Group\n",
    "print('\\n Plot Reaction Times')\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(data=reaction_times_task_cleaned, x='Group', y='ReactionTime', palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Response Time by Condition')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Response Time (ms)')\n",
    "plt.ylim(max_ylim_times_mean)\n",
    "\n",
    "# A closer look: what about individual participants?\n",
    "# Plot Respone time per Participant (to spot Effects Related to Participants)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Participant', y='ReactionTime', hue='Group', data=reaction_times_task_cleaned, palette=color_palette, errorbar='se')\n",
    "plt.title('Mean Response Time per Participant')\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Response Time')\n",
    "plt.ylim(0,max(reaction_times_task_cleaned['ReactionTime'])+2)\n",
    "plt.legend(title='Condition')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Simple two-group case - what test to use?\n",
    "\n",
    "Given that response times are continuous data (in seconds), we could use an independent samples t-test.\n",
    "(Refer to basic statistics books / classes when deciding which tests to use when and why). \n",
    "\n",
    "Note that this kind of test has some assumptions that need to be checked before we can actually do it:\n",
    "\n",
    "1. Independence:\n",
    "    * Design-Based: Ensure that your data collection process guarantees that the observations (or aggregated scores per participant) are independent. This is usually determined by your study design.\n",
    "    ***Our design ensures this.**\n",
    "\n",
    "2. Normality:\n",
    "    * What to Check: The dependent variable (e.g., aggregated reaction time or trust score per participant) should be approximately normally distributed in each group.\n",
    "    * How to Test:\n",
    "        * Shapiro–Wilk Test: Provides a statistical test for normality.\n",
    "        * Q–Q Plots or Histograms: Visual inspection can help detect deviations from normality.\n",
    "\n",
    "3. Homogeneity of Variances (Equal Variances):\n",
    "    * What to Check: The variances in the two groups should be roughly equal.\n",
    "    * How to Test:\n",
    "        * Levene’s Test: Tests for equality of variances.\n",
    "        * Bartlett’s Test: Another option, but it is more sensitive to departures from normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Aggregated Data Participant\n",
    "participant_rt = reaction_times_task_cleaned.groupby(['Participant', 'Group'])['ReactionTime'].mean().reset_index()\n",
    "participant_rt_mean = participant_rt.groupby(['Group'])['ReactionTime'].mean().reset_index()\n",
    "participant_rt_sd = participant_rt.groupby(['Group'])['ReactionTime'].std().reset_index()\n",
    "\n",
    "print(\"\\nAggregated Response Time Data\")\n",
    "print(\"Means:\")\n",
    "print(participant_rt_mean)\n",
    "print(\"Std:\")\n",
    "print(participant_rt_sd)\n",
    "\n",
    "# Separate Reaction Times by Group\n",
    "rt_no_xp = participant_rt.loc[participant_rt['Group'] == 'No-XP', 'ReactionTime']\n",
    "rt_cf_xp = participant_rt.loc[participant_rt['Group'] == 'CF-XP', 'ReactionTime']\n",
    "\n",
    "### 1. Normality Tests\n",
    "print(\"\\nPerform Shapiro-Wilk Tests to Check Normality\")\n",
    "print(\"\\nInterpretation: p > 0.05 indicates that the data do not significantly deviate from a normal distribution.\")\n",
    "# Shapiro-Wilk Test for No-XP group\n",
    "shapiro_no_xp = stats.shapiro(rt_no_xp)\n",
    "print(f\"Shapiro-Wilk (No-XP): W={shapiro_no_xp.statistic:.3f}, p={shapiro_no_xp.pvalue:.3f}\")\n",
    "\n",
    "# Shapiro-Wilk Test for CF-XP group\n",
    "shapiro_cf_xp = stats.shapiro(rt_cf_xp)\n",
    "print(f\"Shapiro-Wilk (CF-XP): W={shapiro_cf_xp.statistic:.3f}, p={shapiro_cf_xp.pvalue:.3f}\")\n",
    "\n",
    "### 2. Homogeneity of Variances\n",
    "\n",
    "# Levene's Test for equal variances\n",
    "print(\"\\nPerform Levene's Test to Check for Equal Variances\")\n",
    "print(\"\\nInterpretation: p > 0.05 indicates that the group variances can be assumed equal.\")\n",
    "levene_test = stats.levene(rt_no_xp, rt_cf_xp)\n",
    "print(f\"Levene's Test: W={levene_test.statistic:.3f}, p={levene_test.pvalue:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** For our response time data, independence, normality and homogeneity of variances is given, so we can proceed with the t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the independent samples t-test\n",
    "t_stat, p_val = stats.ttest_ind(rt_no_xp, rt_cf_xp, equal_var=True)  # Use equal_var=False for Welch's t-test if variances differ\n",
    "\n",
    "t_df = len(rt_no_xp) + len(rt_cf_xp) - 2\n",
    "\n",
    "print(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.25f}\")\n",
    "print(f\"Degrees of freedom: \",t_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "Sucess! We can now report that responses times between groups did indeed differ, with the Counterfactual group taking significanly longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. How to Report Results in a Paper?\n",
    "\n",
    "This is an example excerpt how these insights could look like in a paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "From the 60 participants we recruited, data from one participant was excluded as their reaction time was more than 3 SDs lower than the sample mean.\n",
    "Three additional participants were excluded, given that their response patterns were uniform across all 20 items, suggesting a lack of engagement or indiscriminate responding that compromised the validity of their data.\n",
    "Thus, the final analysis includes data from 56 participants randomly assigned to the two groups, with 29 participants in group CF-XP (14 male / 15 female), and 27 in group No-XP (13 male / 14 female). \n",
    "There were not statistically reliable differences in terms of gender distribution between groups.\n",
    "On average, participants needed 5.74 minutes (*SD*=0.48) to complete the study.\n",
    "\n",
    "In terms of reported trust, participants in the CF-XP group (*M*=4.20, *SD*=0.43), compared to participants in the No-XP group (*M*=3.38, *SD*=0.48), showed significantly higher trust scores (*U*= 87.00, *p* < .000).\n",
    "Group differences were also statistically significant for response time data (*t*(54) = 15.12, *p* < .000) with participants in the CF-XP group (*M*=18.45, *SD*=0.52) taking significantly longer than participants in the No-XP group (*M*=15.89, *SD*=0.74)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
